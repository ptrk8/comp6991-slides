<!-- markdownlint-disable MD005 MD012 MD013 MD007 MD024 -->

# COMP6991 Workshop 8

---

# Contents

1. Threading (spawn and scope)
2. Synchronisation and Locking primitives (Arc, Mutex, etc.)
3. The `Send` and `Sync` traits.

---

# Concurrency vs. Parrallelism

* Although concurrency and parallelism are often used interchangeably, they mean different things.

## Concurrency

* When multiple processes run on a single CPU core by *context switching* between processes.
* In other words, only one process can make progress at any given time.
* This is also known as "time-sharing" a CPU core.
## Parrallelism

* When multiple processes run on multiple CPU cores.
* In other words, `N` processes running on `N` different CPU cores would be able to make progress at the same time.

---

# Concurrency illustrated

* In this example, there are two processes `P1` and `P2` but one CPU core.
* Either `P1` or `P2` can make progress at any given time.
* The operating systems decides when to *context-switch* between `P1` and `P2`.
* This example illustrates two processes **concurrently** running.

```
~~~plantuml -utxt -pipe
@startuml
left to right direction
rectangle P1 as p11
rectangle P1 as p12
rectangle P2 as p21
rectangle P2 as p22
rectangle P1 as p13
rectangle P1 as p14

p11 .d..> p12
p12 .r.> p21
p21 .d..> p22
p22 .l.> p13
p13 .d..> p14
@enduml
~~~
```

---

# Parrallelism illustrated

* In this example, there are four processes `P1`, `P2`, `P3`, `P4` and four CPU cores.
* All four processes are running at the exact same time in **parallel**.

```
~~~plantuml -utxt -pipe
@startuml
top to bottom direction

rectangle P1 as p11
rectangle P1 as p12
rectangle P2 as p21
rectangle P2 as p22
rectangle P3 as p31
rectangle P3 as p32
rectangle P4 as p41
rectangle P4 as p42

p11 ..d..> p12
p21 ..d..> p22
p31 ..d..> p32
p41 ..d..> p42
@enduml
~~~
```

---

# Threading

* 

---

# How to create a new thread with `spawn`?

* To create a new thread, we call the `thread::spawn` function and pass it a closure containing the code we want to run in the new thread.

## Questions

* What does the following code do? <!-- The example prints some text from a main thread and other text from a new thread: -->
* What does `thread::sleep` do? <!-- It forces a thread to stop its execution for a short duration, allowing a different thread to run -->
* Are these threads executing concurrently or in parallel? <!-- We are simulating concurrency because the `thread::sleep` is artificially forcing threads to sleep, which interleaves the thread. -->
* What should I expect to see in the output?
    * Is there anything strange about the output? Why is this happening? <!-- Even though we told the spawned thread to print until i is 9, it only got to 5 before the main thread shut down. -->
* What happens to the output if I run the following one more time? <!-- The order changes. This is because the operating system scheduler is non-deterministic. -->
* Which thread is guaranteed to start running first in the following code? <!-- Trick question. We don't know because the scheduler is non-deterministic. -->

```rust
use std::thread;
use std::time::Duration;

fn main() {
    thread::spawn(|| {
        for i in 1..10 {
            println!("hi number {} from the spawned thread!", i);
            thread::sleep(Duration::from_millis(1));
        }
    });

    for i in 1..5 {
        println!("hi number {} from the main thread!", i);
        thread::sleep(Duration::from_millis(1));
    }
}
```

---

# What happens if I remove `thread::sleep`?

```rust
use std::thread;
use std::time::Duration;

fn main() {
    thread::spawn(|| {
        for i in 1..10 {
            println!("hi number {} from the spawned thread!", i);
        }
    });

    for i in 1..5 {
        println!("hi number {} from the main thread!", i);
    }
}
```

## Question

* Are these threads executing concurrently or in parallel? <!-- On operating systems that map user threads to kernel threads, which is pretty much all operating systems, threads execute in parallel.  -->
* Based on the output, what might be happening behind the scenes in the operating system?

---

# How to wait for all threads to finish?

* What if I want to wait for child threads to finish before exiting my program?
* We use `join` handles.
    * The return type of thread::spawn is `JoinHandle`.
    * A `JoinHandle` is an owned value that, when we call the join method on it, will wait for its thread to finish. 

```rust
use std::thread;
use std::time::Duration;

fn main() {
    let handle = thread::spawn(|| {
        for i in 1..10 {
            println!("hi number {} from the spawned thread!", i);
            thread::sleep(Duration::from_millis(1));
        }
    });

    for i in 1..5 {
        println!("hi number {} from the main thread!", i);
        thread::sleep(Duration::from_millis(1));
    }

    handle.join().unwrap();
}
```

* In this example, the main thread will wait at `handle.join()` until the child thread is finished.

---

# What happens if we call `handle.join()` earlier?


```rust
use std::thread;
use std::time::Duration;

fn main() {
    let handle = thread::spawn(|| {
        for i in 1..10 {
            println!("hi number {} from the spawned thread!", i);
            thread::sleep(Duration::from_millis(1));
        }
    });

    handle.join().unwrap();

    for i in 1..5 {
        println!("hi number {} from the main thread!", i);
        thread::sleep(Duration::from_millis(1));
    }
}
```

<!-- The main thread will wait for the spawned thread to finish and then run its for loop, so the output won’t be interleaved anymore -->

---

# Using move closures with threads

* What if we want to transfer ownership of values from the main thread to a child thread?

```rust
use std::thread;

fn main() {
    let v = vec![1, 2, 3];

    let handle = thread::spawn(|| {
        println!("Here's a vector: {:?}", v);
    });

    handle.join().unwrap();
}
```

---

# The compiler error

* The closure is trying to borrow `v` because `println!` only needs a reference to `v`.
* But the compiler doesn't know how long the spawned thread will run, so it doesn’t know if the reference to `v` will always be valid.

```text
$ cargo run
   Compiling threads v0.1.0 (file:///projects/threads)
error[E0373]: closure may outlive the current function, but it borrows `v`, which is owned by the current function
 --> src/main.rs:6:32
  |
6 |     let handle = thread::spawn(|| {
  |                                ^^ may outlive borrowed value `v`
7 |         println!("Here's a vector: {:?}", v);
  |                                           - `v` is borrowed here
  |
note: function requires argument type to outlive `'static`
 --> src/main.rs:6:18
  |
6 |       let handle = thread::spawn(|| {
  |  __________________^
7 | |         println!("Here's a vector: {:?}", v);
8 | |     });
  | |______^
help: to force the closure to take ownership of `v` (and any other referenced variables), use the `move` keyword
  |
6 |     let handle = thread::spawn(move || {
  |                                ++++

For more information about this error, try `rustc --explain E0373`.
error: could not compile `threads` due to previous error
```

---

# An example of why borrowing `v` in a thread is banned

```rust
use std::thread;

fn main() {
    let v = vec![1, 2, 3];

    let handle = thread::spawn(|| {
        println!("Here's a vector: {:?}", v);
    });

    drop(v); // oh no!

    handle.join().unwrap();
}
```

---

# Using the `move` keyword before the closure

* Adding the move keyword before the closure, forces the closure to take ownership of the values it is using rather than allowing Rust to infer that it should borrow the values.

```rust
use std::thread;

fn main() {
    let v = vec![1, 2, 3];

    let handle = thread::spawn(move || {
        println!("Here's a vector: {:?}", v);
    });

    handle.join().unwrap();
}
```

---

# Shared-State Concurrency

* Having multiple threads access the same shared data is called **shared-state concurrency**.
* Two synchronisation primitives that facilitate shared-state conconcurrency are:
    1. Mutex
    2. Arc.

---

# Mutex
* Mutex stands for "Mutual Exclusion", which allows one thread to access some data at any given time.
* Mutexes are also commonly referred to as "locks".
* Mutexes are used to protect data structures shared between multiple threads from *race conditions*.

---

# API for `Mutex<T>`

* Here's how to create a mutex `m` that guards an integer.
* `m.lock()` obtains the lock which prevents other threads from mutating the value protected by `m`.
    * `m.lock()` will fail if another thread holding the lock panicked.
    * We want to panic if this happens, which is why we `unwrap()`.
* `m.lock()` returns a `MutexGuard` smart pointer wrapped in a `LockResult`, which we've unwrapped.
    * The `MutexGuard` smart pointer implements `Deref`, which points to our inner data.
    * The `MutexGuard` smart pointer also implements `Drop`, which releases the lock when a `MutexGuard` goes out of scope.
        * This auto-release feature is unique to Rust.

```rust
use std::sync::Mutex;

fn main() {
    let m = Mutex::new(5);

    {
        let mut num = m.lock().unwrap();
        *num = 6;
    }

    println!("m = {:?}", m);
}
```





